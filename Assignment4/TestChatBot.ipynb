{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Layer, CNN, RNN, Activation\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = [\"centre\",\"north\",\"west\",\"south\",\"east\"]\n",
    "food = [\"afghan\",\"african\",\"afternoon tea\",\"asian oriental\",\"australasian\",\"australian\",\"austrian\",\"barbeque\",\"basque\",\"belgian\",\"bistro\",\"brazilian\",\"british\",\"canapes\",\"cantonese\",\"caribbean\",\"catalan\",\"chinese\",\"christmas\",\"corsica\",\"creative\",\"crossover\",\"cuban\",\"danish\",\"eastern european\",\"english\",\"eritrean\",\"european\",\"french\",\"fusion\",\"gastropub\",\"german\",\"greek\",\"halal\",\"hungarian\",\"indian\",\"indonesian\",\"international\",\"irish\",\"italian\",\"jamaican\",\"japanese\",\"korean\",\"kosher\",\"latin american\",\"lebanese\",\"light bites\",\"malaysian\",\"mediterranean\",\"mexican\",\"middle eastern\",\"modern american\",\"modern eclectic\",\"modern european\",\"modern global\",\"molecular gastronomy\",\"moroccan\",\"new zealand\",\"north african\",\"north american\",\"north indian\",\"northern european\",\"panasian\",\"persian\",\"polish\",\"polynesian\",\"portuguese\",\"romanian\",\"russian\",\"scandinavian\",\"scottish\",\"seafood\",\"singaporean\",\"south african\",\"south indian\",\"spanish\",\"sri lankan\",\"steakhouse\",\"swedish\",\"swiss\",\"thai\",\"the americas\",\"traditional\",\"turkish\",\"tuscan\",\"unusual\",\"vegetarian\",\"venetian\",\"vietnamese\",\"welsh\",\"world\"]\n",
    "pricerange = [\"cheap\",\"moderate\",\"expensive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 - Data Base Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_json('Camrest.json')\n",
    "\n",
    "def db_query(belief_vector, tokenizer):\n",
    "    # parse belief vector and select max\n",
    "    # how to get tensor index of argmax value?\n",
    "    # area_max = argmax(belief_vector[:len(area)]) \n",
    "    \n",
    "    # filter df rows\n",
    "    results = df.loc[df['area']==area and df['pricerange']==pricerange and df['food']==food]\n",
    "    rest_name = results[0]['name']\n",
    "    rest_addr = results[0]['address']\n",
    "    rest_phone = results[0]['phone']\n",
    "    rest_postal = results[0]['postal']\n",
    "    \n",
    "    # tokenize output\n",
    "    \n",
    "    # return tokenized vector\n",
    "    return [name, rest_name, addr, rest_addr, phone, rest_phone, postal, rest_postal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REFERENCES\n",
    "# https://towardsdatascience.com/building-an-ai-chat-bot-e3a05aa3e75f\n",
    "# https://github.com/priya-dwivedi/Deep-Learning/blob/master/qa_chat_bot/memory_network_q4.py\n",
    "\n",
    "max_words = 20\n",
    "vocab_size = 600\n",
    "\n",
    "## 1) Data input\n",
    "inputs = Input(shape=(max_words,))\n",
    "\n",
    "## 2) Intent\n",
    "seq = LSTM(max_words)(inputs) # return sequences?\n",
    "\n",
    "## 3) Belief State\n",
    "belief = Conv1D(max_words, 1, activation='relu')(inputs)\n",
    "belief = Conv1D(max_words*2, 1, activation='relu')(belief)\n",
    "belief = Conv1D(max_words*4, 1, activation='relu')(belief)\n",
    "belief = MaxPoolingID(int(max_words/2))(belief)\n",
    "belief = RNN(10)(belief) # size? return sequences?\n",
    "a_belief = Dense(len(area), activation='softmax')(belief)\n",
    "f_belief = Dense(len(food), activation='softmax')(belief)\n",
    "p_belief = Dense(len(pricerange), activation='softmax')(belief)\n",
    "\n",
    "belief = keras.layers.concatenate([a_belief, f_belief, p_belief])\n",
    "\n",
    "# How to get these to persist?\n",
    "belief_output = Dense(len(area)+len(food)+len(pricerange), activation='linear')(belief) \n",
    "\n",
    "# Need to dynamically call db query\n",
    "\n",
    "## 4) Database query\n",
    "db_result = Input(shape=(8,))\n",
    "\n",
    "## 5) Policy\n",
    "policy = keras.layers.concatenate([seq, belief, db_result]) \n",
    "policy = Dense(64, activation='tanh')(policy)\n",
    "\n",
    "## 6) Decode response\n",
    "response = LSTM(32)(policy)\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size, activation='softmax')(answer)\n",
    "\n",
    "model = Model(inputs=[inputs, db_result], outputs=[response, belief_output])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2 - Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBQuery(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.db = pd.read_json('Camrest.json')\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer. --> Can it not have weights?\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(DBQuery, self).build(input_shape)  \n",
    "\n",
    "    def call(self, x):\n",
    "         # parse belief vector and select max\n",
    "        # how to get tensor index of argmax value?\n",
    "        # area_max = argmax(x[:len(area)]) \n",
    "        \n",
    "        \n",
    "        results = self.df.loc[df['area']==area and df['pricerange']==pricerange and df['food']==food]\n",
    "        rest_name = results[0]['name']\n",
    "        rest_addr = results[0]['address']\n",
    "        rest_phone = results[0]['phone']\n",
    "        rest_postal = results[0]['postal']\n",
    "        \n",
    "        # How to access external tokenizer?\n",
    "        # How to convert vector to a tensor object?\n",
    "        vector = [name, rest_name, addr, rest_addr, phone, rest_phone, postal, rest_postal]\n",
    "        \n",
    "        return vector\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20\n",
    "vocab_size = 600\n",
    "\n",
    "## 1) Data input\n",
    "inputs = Input(shape=(max_words,))\n",
    "\n",
    "## 2) Intent\n",
    "seq = LSTM(max_words)(inputs) # return sequences?\n",
    "\n",
    "## 3) Belief State\n",
    "belief = Conv1D(max_words, 1, activation='relu')(inputs)\n",
    "belief = Conv1D(max_words*2, 1, activation='relu')(belief)\n",
    "belief = Conv1D(max_words*4, 1, activation='relu')(belief)\n",
    "belief = MaxPoolingID(int(max_words/2))(belief)\n",
    "belief = RNN(10)(belief) # size? return sequences?\n",
    "a_belief = Dense(len(area), activation='softmax')(belief)\n",
    "f_belief = Dense(len(food), activation='softmax')(belief)\n",
    "p_belief = Dense(len(pricerange), activation='softmax')(belief)\n",
    "\n",
    "# How to get these to persist?\n",
    "belief = keras.layers.concatenate([a_belief, f_belief, p_belief])\n",
    "\n",
    "## 4) Database query\n",
    "db_result = DBQuery(8)(belief)\n",
    "\n",
    "## 5) Policy\n",
    "policy = keras.layers.concatenate([seq, belief, db_result]) \n",
    "policy = Dense(64, activation='tanh')(policy)\n",
    "\n",
    "## 6) Decode response\n",
    "response = LSTM(32)(policy)\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size, activation='softmax')(answer)\n",
    "\n",
    "model = Model(inputs=[inputs, db_result], outputs=[response, belief_output])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "import os\n",
    "from time import time\n",
    "import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_CPU=mp.cpu_count()\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=8,\\\n",
    "        inter_op_parallelism_threads=8, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : 0})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 1.4040 - acc: 0.4948 - val_loss: 1.2460 - val_acc: 0.5517\n",
      "Epoch 2/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 1.3294 - acc: 0.5273 - val_loss: 1.1895 - val_acc: 0.5760\n",
      "Epoch 3/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 1.2715 - acc: 0.5462 - val_loss: 1.1395 - val_acc: 0.5928\n",
      "Epoch 4/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 1.2205 - acc: 0.5685 - val_loss: 1.0972 - val_acc: 0.6142\n",
      "Epoch 5/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 1.1812 - acc: 0.5821 - val_loss: 1.0276 - val_acc: 0.6361\n",
      "Epoch 6/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 1.1433 - acc: 0.5968 - val_loss: 1.0328 - val_acc: 0.6341\n",
      "Epoch 7/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 1.1157 - acc: 0.6033 - val_loss: 0.9587 - val_acc: 0.6601\n",
      "Epoch 8/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 1.0911 - acc: 0.6142 - val_loss: 0.9322 - val_acc: 0.6700\n",
      "Epoch 9/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 1.0614 - acc: 0.6254 - val_loss: 1.0451 - val_acc: 0.6378\n",
      "Epoch 10/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 1.0406 - acc: 0.6347 - val_loss: 0.8894 - val_acc: 0.6908\n",
      "Epoch 11/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 1.0193 - acc: 0.6403 - val_loss: 0.9029 - val_acc: 0.6857\n",
      "Epoch 12/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.9952 - acc: 0.6484 - val_loss: 0.9429 - val_acc: 0.6739\n",
      "Epoch 13/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.9834 - acc: 0.6540 - val_loss: 1.0318 - val_acc: 0.6439\n",
      "Epoch 14/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.9654 - acc: 0.6595 - val_loss: 0.8572 - val_acc: 0.6976\n",
      "Epoch 15/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.9525 - acc: 0.6663 - val_loss: 0.8533 - val_acc: 0.7021\n",
      "Epoch 16/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.9411 - acc: 0.6715 - val_loss: 0.9079 - val_acc: 0.6851\n",
      "Epoch 17/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.9233 - acc: 0.6769 - val_loss: 0.8718 - val_acc: 0.7015\n",
      "Epoch 18/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.9114 - acc: 0.6818 - val_loss: 0.8277 - val_acc: 0.7180\n",
      "Epoch 19/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.9053 - acc: 0.6853 - val_loss: 0.8319 - val_acc: 0.7128\n",
      "Epoch 20/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8939 - acc: 0.6902 - val_loss: 0.8411 - val_acc: 0.7124\n",
      "Epoch 21/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8846 - acc: 0.6935 - val_loss: 0.7790 - val_acc: 0.7309\n",
      "Epoch 22/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.8807 - acc: 0.6924 - val_loss: 0.8078 - val_acc: 0.7181\n",
      "Epoch 23/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8761 - acc: 0.6961 - val_loss: 0.8204 - val_acc: 0.7205\n",
      "Epoch 24/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.8676 - acc: 0.7012 - val_loss: 0.7887 - val_acc: 0.7352\n",
      "Epoch 25/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8597 - acc: 0.7022 - val_loss: 0.7257 - val_acc: 0.7543\n",
      "Epoch 26/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8573 - acc: 0.7025 - val_loss: 0.7738 - val_acc: 0.7342\n",
      "Epoch 27/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8521 - acc: 0.7072 - val_loss: 0.7575 - val_acc: 0.7457\n",
      "Epoch 28/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8505 - acc: 0.7071 - val_loss: 0.7527 - val_acc: 0.7416\n",
      "Epoch 29/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8414 - acc: 0.7115 - val_loss: 0.7437 - val_acc: 0.7542\n",
      "Epoch 30/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8423 - acc: 0.7087 - val_loss: 0.7607 - val_acc: 0.7401\n",
      "Epoch 31/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8419 - acc: 0.7105 - val_loss: 0.8027 - val_acc: 0.7274\n",
      "Epoch 32/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8376 - acc: 0.7152 - val_loss: 0.8003 - val_acc: 0.7258\n",
      "Epoch 33/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8308 - acc: 0.7145 - val_loss: 0.7413 - val_acc: 0.7506\n",
      "Epoch 34/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8248 - acc: 0.7186 - val_loss: 0.7911 - val_acc: 0.7401\n",
      "Epoch 35/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8231 - acc: 0.7194 - val_loss: 0.7531 - val_acc: 0.7448\n",
      "Epoch 36/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8180 - acc: 0.7196 - val_loss: 0.7432 - val_acc: 0.7509\n",
      "Epoch 37/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8165 - acc: 0.7215 - val_loss: 0.7696 - val_acc: 0.7380\n",
      "Epoch 38/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8145 - acc: 0.7209 - val_loss: 0.7088 - val_acc: 0.7579\n",
      "Epoch 39/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8095 - acc: 0.7221 - val_loss: 0.7661 - val_acc: 0.7404\n",
      "Epoch 40/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8091 - acc: 0.7246 - val_loss: 0.7692 - val_acc: 0.7516\n",
      "Epoch 41/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8038 - acc: 0.7279 - val_loss: 0.7592 - val_acc: 0.7535\n",
      "Epoch 42/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8029 - acc: 0.7272 - val_loss: 0.7296 - val_acc: 0.7564\n",
      "Epoch 43/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8044 - acc: 0.7263 - val_loss: 0.7049 - val_acc: 0.7642\n",
      "Epoch 44/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7974 - acc: 0.7291 - val_loss: 0.7009 - val_acc: 0.7633\n",
      "Epoch 45/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7954 - acc: 0.7301 - val_loss: 0.6807 - val_acc: 0.7743\n",
      "Epoch 46/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7961 - acc: 0.7270 - val_loss: 0.7238 - val_acc: 0.7602\n",
      "Epoch 47/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7951 - acc: 0.7313 - val_loss: 0.7936 - val_acc: 0.7423\n",
      "Epoch 48/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7949 - acc: 0.7287 - val_loss: 0.7140 - val_acc: 0.7705\n",
      "Epoch 49/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7870 - acc: 0.7345 - val_loss: 0.7553 - val_acc: 0.7490\n",
      "Epoch 50/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7883 - acc: 0.7330 - val_loss: 0.7450 - val_acc: 0.7487\n",
      "Epoch 51/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7914 - acc: 0.7326 - val_loss: 0.7306 - val_acc: 0.7589\n",
      "Epoch 52/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7847 - acc: 0.7344 - val_loss: 0.6837 - val_acc: 0.7643\n",
      "Epoch 53/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7809 - acc: 0.7362 - val_loss: 0.6890 - val_acc: 0.7696\n",
      "Epoch 54/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7825 - acc: 0.7366 - val_loss: 0.7153 - val_acc: 0.7580\n",
      "Epoch 55/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7867 - acc: 0.7334 - val_loss: 0.7175 - val_acc: 0.7579\n",
      "Epoch 56/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7885 - acc: 0.7353 - val_loss: 0.7377 - val_acc: 0.7566\n",
      "Epoch 57/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7826 - acc: 0.7361 - val_loss: 0.7414 - val_acc: 0.7520\n",
      "Epoch 58/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7842 - acc: 0.7357 - val_loss: 0.6693 - val_acc: 0.7772\n",
      "Epoch 59/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7821 - acc: 0.7346 - val_loss: 0.8174 - val_acc: 0.7261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7791 - acc: 0.7375 - val_loss: 0.7208 - val_acc: 0.7582\n",
      "Epoch 61/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7773 - acc: 0.7364 - val_loss: 0.7074 - val_acc: 0.7626\n",
      "Epoch 62/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7816 - acc: 0.7350 - val_loss: 0.7771 - val_acc: 0.7399\n",
      "Epoch 63/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7826 - acc: 0.7361 - val_loss: 0.7023 - val_acc: 0.7639\n",
      "Epoch 64/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7739 - acc: 0.7414 - val_loss: 0.6700 - val_acc: 0.7798\n",
      "Epoch 65/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7790 - acc: 0.7375 - val_loss: 0.6878 - val_acc: 0.7688\n",
      "Epoch 66/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7803 - acc: 0.7368 - val_loss: 0.8417 - val_acc: 0.7386\n",
      "Epoch 67/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7762 - acc: 0.7380 - val_loss: 0.6482 - val_acc: 0.7864\n",
      "Epoch 68/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7766 - acc: 0.7391 - val_loss: 0.6773 - val_acc: 0.7724\n",
      "Epoch 69/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7810 - acc: 0.7382 - val_loss: 0.8326 - val_acc: 0.7292\n",
      "Epoch 70/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7833 - acc: 0.7378 - val_loss: 0.7049 - val_acc: 0.7764\n",
      "Epoch 71/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7795 - acc: 0.7397 - val_loss: 0.6802 - val_acc: 0.7712\n",
      "Epoch 72/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7792 - acc: 0.7392 - val_loss: 0.8012 - val_acc: 0.7417\n",
      "Epoch 73/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7792 - acc: 0.7395 - val_loss: 0.7336 - val_acc: 0.7490\n",
      "Epoch 74/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7791 - acc: 0.7391 - val_loss: 0.7235 - val_acc: 0.7580\n",
      "Epoch 75/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7810 - acc: 0.7391 - val_loss: 0.7283 - val_acc: 0.7508\n",
      "Epoch 76/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7789 - acc: 0.7397 - val_loss: 0.7102 - val_acc: 0.7657\n",
      "Epoch 77/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7776 - acc: 0.7414 - val_loss: 0.7312 - val_acc: 0.7542\n",
      "Epoch 78/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7825 - acc: 0.7393 - val_loss: 0.7161 - val_acc: 0.7675\n",
      "Epoch 79/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7848 - acc: 0.7376 - val_loss: 0.7594 - val_acc: 0.7440\n",
      "Epoch 80/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7839 - acc: 0.7387 - val_loss: 0.7532 - val_acc: 0.7646\n",
      "Epoch 81/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7842 - acc: 0.7374 - val_loss: 0.7039 - val_acc: 0.7720\n",
      "Epoch 82/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7788 - acc: 0.7398 - val_loss: 0.8164 - val_acc: 0.7384\n",
      "Epoch 83/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7818 - acc: 0.7392 - val_loss: 0.7563 - val_acc: 0.7555\n",
      "Epoch 84/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7788 - acc: 0.7415 - val_loss: 0.8308 - val_acc: 0.7233\n",
      "Epoch 85/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7877 - acc: 0.7375 - val_loss: 0.6961 - val_acc: 0.7782\n",
      "Epoch 86/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7877 - acc: 0.7365 - val_loss: 0.7392 - val_acc: 0.7561\n",
      "Epoch 87/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7892 - acc: 0.7379 - val_loss: 0.7807 - val_acc: 0.7494\n",
      "Epoch 88/100\n",
      "1563/1562 [==============================] - 108s 69ms/step - loss: 0.7892 - acc: 0.7360 - val_loss: 0.7510 - val_acc: 0.7561\n",
      "Epoch 89/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7912 - acc: 0.7372 - val_loss: 0.7654 - val_acc: 0.7442\n",
      "Epoch 90/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7896 - acc: 0.7397 - val_loss: 0.6469 - val_acc: 0.7833\n",
      "Epoch 91/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7979 - acc: 0.7347 - val_loss: 0.9355 - val_acc: 0.7137\n",
      "Epoch 92/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7972 - acc: 0.7359 - val_loss: 0.6957 - val_acc: 0.7697\n",
      "Epoch 93/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7966 - acc: 0.7356 - val_loss: 0.7869 - val_acc: 0.7339\n",
      "Epoch 94/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7948 - acc: 0.7374 - val_loss: 0.7142 - val_acc: 0.7625\n",
      "Epoch 95/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7959 - acc: 0.7389 - val_loss: 0.7387 - val_acc: 0.7684\n",
      "Epoch 96/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.7973 - acc: 0.7355 - val_loss: 0.6895 - val_acc: 0.7739\n",
      "Epoch 97/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7951 - acc: 0.7360 - val_loss: 0.7378 - val_acc: 0.7561\n",
      "Epoch 98/100\n",
      "1563/1562 [==============================] - 107s 69ms/step - loss: 0.8009 - acc: 0.7361 - val_loss: 0.7168 - val_acc: 0.7667\n",
      "Epoch 99/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.7998 - acc: 0.7356 - val_loss: 0.6623 - val_acc: 0.7821\n",
      "Epoch 100/100\n",
      "1563/1562 [==============================] - 107s 68ms/step - loss: 0.8008 - acc: 0.7335 - val_loss: 0.8414 - val_acc: 0.7259\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True, callbacks=[tensorboard])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4,\n",
    "                        steps_per_epoch=len(x_train)/batch_size, \n",
    "                        callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /home/ubuntu/code/DeepNeuralNetworksandAI/Assignment1/part2/saved_models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 6s 553us/step\n",
      "Test loss: 0.8414081791877747\n",
      "Test accuracy: 0.7259\n",
      "CPU Start: 00:00:00\n",
      "CPU End: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "end = time()\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('CPU Start:', str(start))\n",
    "print('CPU End:', str(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548552426.282937"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_CPU=mp.cpu_count()\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=8,\\\n",
    "        inter_op_parallelism_threads=8, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : 1})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      " 249/1562 [===>..........................] - ETA: 1:26 - loss: 2.2036 - acc: 0.1756"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cee909db711d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                         callbacks=[tensorboard])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True, callbacks=[tensorboard])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4,\n",
    "                        steps_per_epoch=len(x_train)/batch_size,\n",
    "                        callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpu_keras_cifar10_trained_model.h5'\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "end = time()\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('GPU Runtime:', str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

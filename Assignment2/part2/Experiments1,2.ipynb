{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.callbacks import TensorBoard, TerminateOnNaN, LearningRateScheduler, Callback\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = pickle.load( open( \"../imagenet-200/train_images.pkl\", \"rb\" ) )\n",
    "train_labels = pickle.load( open( \"../imagenet-200/train_labels.pkl\", \"rb\" ) )\n",
    "val_images = pickle.load( open( \"../imagenet-200/val_images.pkl\", \"rb\" ) )\n",
    "val_labels = pickle.load( open( \"../imagenet-200/val_labels.pkl\", \"rb\" ) )\n",
    "y_train = pickle.load( open( \"../imagenet-200/y_train.pkl\", \"rb\" ) )\n",
    "y_test = pickle.load( open( \"../imagenet-200/y_test.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02119789</td>\n",
       "      <td>1</td>\n",
       "      <td>kit_fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n02100735</td>\n",
       "      <td>2</td>\n",
       "      <td>English_setter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02110185</td>\n",
       "      <td>3</td>\n",
       "      <td>Siberian_husky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n02096294</td>\n",
       "      <td>4</td>\n",
       "      <td>Australian_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n02102040</td>\n",
       "      <td>5</td>\n",
       "      <td>English_springer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  id         description\n",
       "0  n02119789   1             kit_fox\n",
       "1  n02100735   2      English_setter\n",
       "2  n02110185   3      Siberian_husky\n",
       "3  n02096294   4  Australian_terrier\n",
       "4  n02102040   5    English_springer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_labels = pd.read_csv('../imagenet-200/map_clsloc.txt', sep='\\s', header=None, engine='python')\n",
    "text_labels.columns=['label', 'id', 'description']\n",
    "text_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704    barbershop\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "plotData = train_images[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(text_labels.loc[text_labels['label']==train_labels[0], 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547    cash_machine\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "plotData = val_images[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(text_labels.loc[text_labels['label']==val_labels[0], 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "val_images = val_images.astype('float32')\n",
    "train_images /= 255\n",
    "val_images /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "y_test = []\n",
    "for row in train_labels:\n",
    "    label = text_labels.loc[text_labels['label']==row]['id'].iloc[0]\n",
    "    y_train.append(label)\n",
    "\n",
    "for row in val_labels:\n",
    "    label = text_labels.loc[text_labels['label']==row]['id'].iloc[0]\n",
    "    y_test.append(label)\n",
    "    \n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "y_train = enc.fit_transform(train_labels.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(val_labels.reshape(-1, 1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['n01443537', 'n01629819', 'n01641577', 'n01644900', 'n01698640',\n",
       "        'n01742172', 'n01768244', 'n01770393', 'n01774384', 'n01774750',\n",
       "        'n01784675', 'n01855672', 'n01882714', 'n01910747', 'n01917289',\n",
       "        'n01944390', 'n01945685', 'n01950731', 'n01983481', 'n01984695',\n",
       "        'n02002724', 'n02056570', 'n02058221', 'n02074367', 'n02085620',\n",
       "        'n02094433', 'n02099601', 'n02099712', 'n02106662', 'n02113799',\n",
       "        'n02123045', 'n02123394', 'n02124075', 'n02125311', 'n02129165',\n",
       "        'n02132136', 'n02165456', 'n02190166', 'n02206856', 'n02226429',\n",
       "        'n02231487', 'n02233338', 'n02236044', 'n02268443', 'n02279972',\n",
       "        'n02281406', 'n02321529', 'n02364673', 'n02395406', 'n02403003',\n",
       "        'n02410509', 'n02415577', 'n02423022', 'n02437312', 'n02480495',\n",
       "        'n02481823', 'n02486410', 'n02504458', 'n02509815', 'n02666196',\n",
       "        'n02669723', 'n02699494', 'n02730930', 'n02769748', 'n02788148',\n",
       "        'n02791270', 'n02793495', 'n02795169', 'n02802426', 'n02808440',\n",
       "        'n02814533', 'n02814860', 'n02815834', 'n02823428', 'n02837789',\n",
       "        'n02841315', 'n02843684', 'n02883205', 'n02892201', 'n02906734',\n",
       "        'n02909870', 'n02917067', 'n02927161', 'n02948072', 'n02950826',\n",
       "        'n02963159', 'n02977058', 'n02988304', 'n02999410', 'n03014705',\n",
       "        'n03026506', 'n03042490', 'n03085013', 'n03089624', 'n03100240',\n",
       "        'n03126707', 'n03160309', 'n03179701', 'n03201208', 'n03250847',\n",
       "        'n03255030', 'n03355925', 'n03388043', 'n03393912', 'n03400231',\n",
       "        'n03404251', 'n03424325', 'n03444034', 'n03447447', 'n03544143',\n",
       "        'n03584254', 'n03599486', 'n03617480', 'n03637318', 'n03649909',\n",
       "        'n03662601', 'n03670208', 'n03706229', 'n03733131', 'n03763968',\n",
       "        'n03770439', 'n03796401', 'n03804744', 'n03814639', 'n03837869',\n",
       "        'n03838899', 'n03854065', 'n03891332', 'n03902125', 'n03930313',\n",
       "        'n03937543', 'n03970156', 'n03976657', 'n03977966', 'n03980874',\n",
       "        'n03983396', 'n03992509', 'n04008634', 'n04023962', 'n04067472',\n",
       "        'n04070727', 'n04074963', 'n04099969', 'n04118538', 'n04133789',\n",
       "        'n04146614', 'n04149813', 'n04179913', 'n04251144', 'n04254777',\n",
       "        'n04259630', 'n04265275', 'n04275548', 'n04285008', 'n04311004',\n",
       "        'n04328186', 'n04356056', 'n04366367', 'n04371430', 'n04376876',\n",
       "        'n04398044', 'n04399382', 'n04417672', 'n04456115', 'n04465501',\n",
       "        'n04486054', 'n04487081', 'n04501370', 'n04507155', 'n04532106',\n",
       "        'n04532670', 'n04540053', 'n04560804', 'n04562935', 'n04596742',\n",
       "        'n04597913', 'n06596364', 'n07579787', 'n07583066', 'n07614500',\n",
       "        'n07615774', 'n07695742', 'n07711569', 'n07715103', 'n07720875',\n",
       "        'n07734744', 'n07747607', 'n07749582', 'n07753592', 'n07768694',\n",
       "        'n07871810', 'n07873807', 'n07875152', 'n07920052', 'n09193705',\n",
       "        'n09246464', 'n09256479', 'n09332890', 'n09428293', 'n12267677'],\n",
       "       dtype='<U9')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_train, open( \"../imagenet-200/y_train.pkl\", \"wb\" ) )\n",
    "pickle.dump(y_test, open( \"../imagenet-200/y_test.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(enc, open( \"../imagenet-200/encoder.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, y_train = shuffle(train_images, train_labels, y_train, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label   id description\n",
      "812  n07583066  813   guacamole\n"
     ]
    }
   ],
   "source": [
    "plotData = train_images[0]\n",
    "plt.imshow(plotData)\n",
    "plt.show()\n",
    "print(text_labels.loc[text_labels['label']==train_labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "First we will select an optimizer for the task. We will start with a smaller number of epochs to eliminate any that are obviously poor choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.2982 - acc: 0.0052 - val_loss: 5.2933 - val_acc: 0.0059\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.2358 - acc: 0.0096 - val_loss: 5.1405 - val_acc: 0.0113\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1478 - acc: 0.0128 - val_loss: 5.0788 - val_acc: 0.0182\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0939 - acc: 0.0174 - val_loss: 4.9952 - val_acc: 0.0296\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0258 - acc: 0.0234 - val_loss: 4.8967 - val_acc: 0.0385\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9411 - acc: 0.0317 - val_loss: 4.7850 - val_acc: 0.0496\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8614 - acc: 0.0387 - val_loss: 4.7128 - val_acc: 0.0599\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7902 - acc: 0.0462 - val_loss: 4.6497 - val_acc: 0.0657\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7283 - acc: 0.0521 - val_loss: 4.6031 - val_acc: 0.0665\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6744 - acc: 0.0587 - val_loss: 4.5275 - val_acc: 0.0788\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6280 - acc: 0.0647 - val_loss: 4.4615 - val_acc: 0.0880\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5830 - acc: 0.0706 - val_loss: 4.4305 - val_acc: 0.0939\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5409 - acc: 0.0760 - val_loss: 4.3853 - val_acc: 0.0943\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5050 - acc: 0.0816 - val_loss: 4.3523 - val_acc: 0.1005\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4708 - acc: 0.0868 - val_loss: 4.3456 - val_acc: 0.0964\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4376 - acc: 0.0893 - val_loss: 4.2849 - val_acc: 0.1062\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4078 - acc: 0.0931 - val_loss: 4.2400 - val_acc: 0.1165\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3811 - acc: 0.0969 - val_loss: 4.2200 - val_acc: 0.1150\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3562 - acc: 0.1006 - val_loss: 4.2318 - val_acc: 0.1136\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3361 - acc: 0.1032 - val_loss: 4.1650 - val_acc: 0.1234\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3074 - acc: 0.1067 - val_loss: 4.1405 - val_acc: 0.1278\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2864 - acc: 0.1098 - val_loss: 4.1719 - val_acc: 0.1237\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2615 - acc: 0.1119 - val_loss: 4.1302 - val_acc: 0.1299\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2445 - acc: 0.1147 - val_loss: 4.2019 - val_acc: 0.1206\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2264 - acc: 0.1174 - val_loss: 4.1289 - val_acc: 0.1295\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2088 - acc: 0.1194 - val_loss: 4.1744 - val_acc: 0.1202\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1874 - acc: 0.1221 - val_loss: 4.1749 - val_acc: 0.1229\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1771 - acc: 0.1242 - val_loss: 4.0753 - val_acc: 0.1412\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 4.1562 - acc: 0.1259 - val_loss: 4.1757 - val_acc: 0.1222\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1403 - acc: 0.1293 - val_loss: 4.0168 - val_acc: 0.1463\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1272 - acc: 0.1289 - val_loss: 4.1705 - val_acc: 0.1198\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1112 - acc: 0.1322 - val_loss: 4.0494 - val_acc: 0.1385\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1021 - acc: 0.1346 - val_loss: 4.0837 - val_acc: 0.1357\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0830 - acc: 0.1359 - val_loss: 4.0721 - val_acc: 0.1364\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0707 - acc: 0.1379 - val_loss: 4.0735 - val_acc: 0.1348\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0609 - acc: 0.1389 - val_loss: 4.0804 - val_acc: 0.1352\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0474 - acc: 0.1418 - val_loss: 4.0743 - val_acc: 0.1349\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0341 - acc: 0.1437 - val_loss: 4.0432 - val_acc: 0.1412\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0242 - acc: 0.1435 - val_loss: 4.0185 - val_acc: 0.1446\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0090 - acc: 0.1469 - val_loss: 4.0403 - val_acc: 0.1381\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9978 - acc: 0.1466 - val_loss: 4.1210 - val_acc: 0.1287\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9854 - acc: 0.1488 - val_loss: 4.2714 - val_acc: 0.1142\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9778 - acc: 0.1514 - val_loss: 4.1216 - val_acc: 0.1333\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9667 - acc: 0.1522 - val_loss: 4.0706 - val_acc: 0.1378\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9570 - acc: 0.1543 - val_loss: 4.0405 - val_acc: 0.1451\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9447 - acc: 0.1545 - val_loss: 3.9572 - val_acc: 0.1541\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9310 - acc: 0.1562 - val_loss: 3.9463 - val_acc: 0.1540\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 3.9220 - acc: 0.1574 - val_loss: 3.9665 - val_acc: 0.1487\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9109 - acc: 0.1587 - val_loss: 3.9192 - val_acc: 0.1588\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9045 - acc: 0.1610 - val_loss: 3.8916 - val_acc: 0.1597\n",
      "10000/10000 [==============================] - 1s 143us/step\n",
      "Test loss: 3.8916304641723634\n",
      "Test accuracy: 0.1597\n",
      "Runtime: 1234.9703407287598\n",
      "Training RMSprop optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9497 - acc: 0.0327 - val_loss: 4.6417 - val_acc: 0.0590\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7054 - acc: 0.0578 - val_loss: 4.5453 - val_acc: 0.0767\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6665 - acc: 0.0653 - val_loss: 4.5877 - val_acc: 0.0719\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6640 - acc: 0.0648 - val_loss: 4.6474 - val_acc: 0.0651\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6786 - acc: 0.0628 - val_loss: 4.7051 - val_acc: 0.0626\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6987 - acc: 0.0622 - val_loss: 4.7183 - val_acc: 0.0624\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7219 - acc: 0.0590 - val_loss: 4.5778 - val_acc: 0.0723\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7441 - acc: 0.0578 - val_loss: 4.6507 - val_acc: 0.0646\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7820 - acc: 0.0527 - val_loss: 4.6735 - val_acc: 0.0586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8314 - acc: 0.0474 - val_loss: 4.7025 - val_acc: 0.0573\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8661 - acc: 0.0446 - val_loss: 4.7488 - val_acc: 0.0515\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8788 - acc: 0.0425 - val_loss: 4.7716 - val_acc: 0.0485\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8849 - acc: 0.0404 - val_loss: 4.9086 - val_acc: 0.0411\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8923 - acc: 0.0406 - val_loss: 5.0777 - val_acc: 0.0388\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8887 - acc: 0.0394 - val_loss: 4.7517 - val_acc: 0.0524\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8673 - acc: 0.0411 - val_loss: 4.7493 - val_acc: 0.0458\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8601 - acc: 0.0401 - val_loss: 4.7097 - val_acc: 0.0535\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8470 - acc: 0.0425 - val_loss: 4.7704 - val_acc: 0.0481\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8352 - acc: 0.0435 - val_loss: 4.8183 - val_acc: 0.0442\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8278 - acc: 0.0458 - val_loss: 4.8052 - val_acc: 0.0421\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8295 - acc: 0.0450 - val_loss: 4.7031 - val_acc: 0.0524\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8186 - acc: 0.0454 - val_loss: 4.7653 - val_acc: 0.0523\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8247 - acc: 0.0443 - val_loss: 4.7247 - val_acc: 0.0496\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8234 - acc: 0.0449 - val_loss: 4.7317 - val_acc: 0.0519\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8266 - acc: 0.0456 - val_loss: 4.7167 - val_acc: 0.0544\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8279 - acc: 0.0433 - val_loss: 4.7490 - val_acc: 0.0511\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8319 - acc: 0.0445 - val_loss: 4.7456 - val_acc: 0.0505\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8407 - acc: 0.0439 - val_loss: 4.8018 - val_acc: 0.0413\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8390 - acc: 0.0435 - val_loss: 4.7389 - val_acc: 0.0494\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8412 - acc: 0.0437 - val_loss: 4.8182 - val_acc: 0.0416\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8499 - acc: 0.0424 - val_loss: 4.8440 - val_acc: 0.0449\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8590 - acc: 0.0415 - val_loss: 4.9603 - val_acc: 0.0354\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8584 - acc: 0.0407 - val_loss: 4.8370 - val_acc: 0.0374\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8610 - acc: 0.0410 - val_loss: 4.8089 - val_acc: 0.0377\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8612 - acc: 0.0407 - val_loss: 4.8935 - val_acc: 0.0375\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8641 - acc: 0.0404 - val_loss: 4.8408 - val_acc: 0.0406\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8747 - acc: 0.0399 - val_loss: 4.8694 - val_acc: 0.0340\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8770 - acc: 0.0393 - val_loss: 4.7873 - val_acc: 0.0460\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8864 - acc: 0.0385 - val_loss: 4.8266 - val_acc: 0.0361\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8919 - acc: 0.0376 - val_loss: 4.9038 - val_acc: 0.0336\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8899 - acc: 0.0384 - val_loss: 4.7996 - val_acc: 0.0473\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8984 - acc: 0.0370 - val_loss: 4.8612 - val_acc: 0.0366\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8913 - acc: 0.0380 - val_loss: 4.8058 - val_acc: 0.0419\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8998 - acc: 0.0375 - val_loss: 4.8195 - val_acc: 0.0421\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9006 - acc: 0.0376 - val_loss: 4.9566 - val_acc: 0.0338\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9067 - acc: 0.0368 - val_loss: 4.8658 - val_acc: 0.0320\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9069 - acc: 0.0369 - val_loss: 4.8185 - val_acc: 0.0390\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9061 - acc: 0.0370 - val_loss: 4.8666 - val_acc: 0.0355\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9133 - acc: 0.0364 - val_loss: 4.9605 - val_acc: 0.0291\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9130 - acc: 0.0364 - val_loss: 4.8804 - val_acc: 0.0287\n",
      "10000/10000 [==============================] - 1s 126us/step\n",
      "Test loss: 4.8803506820678715\n",
      "Test accuracy: 0.0287\n",
      "Runtime: 1247.7888658046722\n",
      "Training Adagrad optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0430 - acc: 0.0224 - val_loss: 4.7617 - val_acc: 0.0491\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7292 - acc: 0.0516 - val_loss: 4.5426 - val_acc: 0.0745\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5925 - acc: 0.0673 - val_loss: 4.4259 - val_acc: 0.0907\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5171 - acc: 0.0785 - val_loss: 4.3626 - val_acc: 0.0992\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.4562 - acc: 0.0866 - val_loss: 4.2970 - val_acc: 0.1065\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4061 - acc: 0.0919 - val_loss: 4.3206 - val_acc: 0.1043\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3694 - acc: 0.0973 - val_loss: 4.3405 - val_acc: 0.1048\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3333 - acc: 0.1035 - val_loss: 4.2853 - val_acc: 0.1080\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3041 - acc: 0.1048 - val_loss: 4.2710 - val_acc: 0.1101\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2809 - acc: 0.1085 - val_loss: 4.2600 - val_acc: 0.1118\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2562 - acc: 0.1125 - val_loss: 4.2412 - val_acc: 0.1150\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2338 - acc: 0.1155 - val_loss: 4.1637 - val_acc: 0.1252\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2137 - acc: 0.1174 - val_loss: 4.1390 - val_acc: 0.1302\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1987 - acc: 0.1204 - val_loss: 4.2319 - val_acc: 0.1172\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1863 - acc: 0.1222 - val_loss: 4.2110 - val_acc: 0.1191\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1675 - acc: 0.1244 - val_loss: 4.2286 - val_acc: 0.1162\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1510 - acc: 0.1258 - val_loss: 4.1580 - val_acc: 0.1250\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1432 - acc: 0.1275 - val_loss: 4.1890 - val_acc: 0.1215\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1299 - acc: 0.1305 - val_loss: 4.1555 - val_acc: 0.1255\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1236 - acc: 0.1308 - val_loss: 4.1778 - val_acc: 0.1226\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1100 - acc: 0.1333 - val_loss: 4.2052 - val_acc: 0.1174\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0985 - acc: 0.1342 - val_loss: 4.1471 - val_acc: 0.1253\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0925 - acc: 0.1353 - val_loss: 4.1496 - val_acc: 0.1262\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0845 - acc: 0.1360 - val_loss: 4.1684 - val_acc: 0.1223\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0747 - acc: 0.1369 - val_loss: 4.1530 - val_acc: 0.1237\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0631 - acc: 0.1391 - val_loss: 4.1565 - val_acc: 0.1246\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0620 - acc: 0.1400 - val_loss: 4.1971 - val_acc: 0.1196\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0483 - acc: 0.1413 - val_loss: 4.1264 - val_acc: 0.1279\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0443 - acc: 0.1422 - val_loss: 4.0598 - val_acc: 0.1377\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0368 - acc: 0.1428 - val_loss: 4.2253 - val_acc: 0.1180\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0305 - acc: 0.1431 - val_loss: 4.1602 - val_acc: 0.1230\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0269 - acc: 0.1440 - val_loss: 4.1068 - val_acc: 0.1300\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0188 - acc: 0.1449 - val_loss: 4.1372 - val_acc: 0.1270\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0123 - acc: 0.1467 - val_loss: 4.1766 - val_acc: 0.1239\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0030 - acc: 0.1482 - val_loss: 4.1373 - val_acc: 0.1261\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9990 - acc: 0.1476 - val_loss: 4.0761 - val_acc: 0.1321\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9918 - acc: 0.1495 - val_loss: 4.1096 - val_acc: 0.1307\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9908 - acc: 0.1497 - val_loss: 4.1536 - val_acc: 0.1266\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9815 - acc: 0.1502 - val_loss: 4.1080 - val_acc: 0.1300\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9758 - acc: 0.1493 - val_loss: 4.1419 - val_acc: 0.1265\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9753 - acc: 0.1492 - val_loss: 4.1194 - val_acc: 0.1298\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9690 - acc: 0.1520 - val_loss: 4.1092 - val_acc: 0.1300\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9658 - acc: 0.1543 - val_loss: 4.1268 - val_acc: 0.1303\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9614 - acc: 0.1527 - val_loss: 4.0905 - val_acc: 0.1331\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9575 - acc: 0.1542 - val_loss: 4.0526 - val_acc: 0.1372\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9534 - acc: 0.1543 - val_loss: 4.1526 - val_acc: 0.1275\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.9482 - acc: 0.1560 - val_loss: 4.1177 - val_acc: 0.1327\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9403 - acc: 0.1564 - val_loss: 4.1136 - val_acc: 0.1303\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9391 - acc: 0.1569 - val_loss: 4.1067 - val_acc: 0.1333\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9312 - acc: 0.1576 - val_loss: 4.1348 - val_acc: 0.1302\n",
      "10000/10000 [==============================] - 1s 127us/step\n",
      "Test loss: 4.134802265167236\n",
      "Test accuracy: 0.1302\n",
      "Runtime: 1253.2157349586487\n",
      "Training Adadelta optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0688 - acc: 0.0197 - val_loss: 4.8003 - val_acc: 0.0404\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7374 - acc: 0.0538 - val_loss: 4.5508 - val_acc: 0.0770\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5863 - acc: 0.0702 - val_loss: 4.5602 - val_acc: 0.0775\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5066 - acc: 0.0820 - val_loss: 4.3407 - val_acc: 0.1019\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4519 - acc: 0.0892 - val_loss: 4.2902 - val_acc: 0.1038\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4108 - acc: 0.0955 - val_loss: 4.2413 - val_acc: 0.1149\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3816 - acc: 0.0987 - val_loss: 4.2411 - val_acc: 0.1129\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3686 - acc: 0.1008 - val_loss: 4.3086 - val_acc: 0.1061\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3590 - acc: 0.1033 - val_loss: 4.1823 - val_acc: 0.1233\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3488 - acc: 0.1061 - val_loss: 4.2585 - val_acc: 0.1155\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3364 - acc: 0.1084 - val_loss: 4.3537 - val_acc: 0.1040\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3423 - acc: 0.1066 - val_loss: 4.3385 - val_acc: 0.1022\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3320 - acc: 0.1072 - val_loss: 4.2066 - val_acc: 0.1194\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3307 - acc: 0.1083 - val_loss: 4.2385 - val_acc: 0.1162\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3284 - acc: 0.1088 - val_loss: 4.3756 - val_acc: 0.0983\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3311 - acc: 0.1092 - val_loss: 4.3474 - val_acc: 0.1034\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3360 - acc: 0.1089 - val_loss: 4.4212 - val_acc: 0.0930\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3363 - acc: 0.1092 - val_loss: 4.3415 - val_acc: 0.1086\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3319 - acc: 0.1097 - val_loss: 4.3229 - val_acc: 0.1029\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3295 - acc: 0.1077 - val_loss: 4.3954 - val_acc: 0.0960\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3324 - acc: 0.1092 - val_loss: 4.2541 - val_acc: 0.1120\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3340 - acc: 0.1097 - val_loss: 4.4092 - val_acc: 0.0975\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3355 - acc: 0.1098 - val_loss: 4.2614 - val_acc: 0.1139\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3351 - acc: 0.1095 - val_loss: 4.1202 - val_acc: 0.1311\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3396 - acc: 0.1092 - val_loss: 4.4107 - val_acc: 0.0954\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3356 - acc: 0.1088 - val_loss: 4.4070 - val_acc: 0.0974\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3386 - acc: 0.1085 - val_loss: 4.4761 - val_acc: 0.0885\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3387 - acc: 0.1086 - val_loss: 4.2466 - val_acc: 0.1161\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3402 - acc: 0.1079 - val_loss: 4.3862 - val_acc: 0.1019\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3423 - acc: 0.1081 - val_loss: 4.2275 - val_acc: 0.1104\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3452 - acc: 0.1086 - val_loss: 4.4524 - val_acc: 0.0967\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3498 - acc: 0.1073 - val_loss: 4.4561 - val_acc: 0.0919\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3468 - acc: 0.1082 - val_loss: 4.4930 - val_acc: 0.0921\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 27s 9ms/step - loss: 4.3447 - acc: 0.1069 - val_loss: 4.2863 - val_acc: 0.1085\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3521 - acc: 0.1067 - val_loss: 4.4492 - val_acc: 0.0914\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3554 - acc: 0.1065 - val_loss: 4.3215 - val_acc: 0.1053\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3551 - acc: 0.1060 - val_loss: 4.4305 - val_acc: 0.0925\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3612 - acc: 0.1062 - val_loss: 4.3812 - val_acc: 0.1010\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3585 - acc: 0.1065 - val_loss: 4.3681 - val_acc: 0.1030\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3649 - acc: 0.1059 - val_loss: 4.3717 - val_acc: 0.0966\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3663 - acc: 0.1059 - val_loss: 4.2144 - val_acc: 0.1163\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3683 - acc: 0.1050 - val_loss: 4.6620 - val_acc: 0.0771\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3685 - acc: 0.1065 - val_loss: 4.2637 - val_acc: 0.1100\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3692 - acc: 0.1041 - val_loss: 4.4826 - val_acc: 0.0937\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3709 - acc: 0.1054 - val_loss: 4.4205 - val_acc: 0.0958\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3698 - acc: 0.1046 - val_loss: 4.4221 - val_acc: 0.0907\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.3792 - acc: 0.1034 - val_loss: 4.3911 - val_acc: 0.0961\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3795 - acc: 0.1044 - val_loss: 4.4331 - val_acc: 0.0910\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3803 - acc: 0.1042 - val_loss: 4.3320 - val_acc: 0.1034\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3815 - acc: 0.1041 - val_loss: 4.4073 - val_acc: 0.0900\n",
      "10000/10000 [==============================] - 1s 129us/step\n",
      "Test loss: 4.407295335388183\n",
      "Test accuracy: 0.09\n",
      "Runtime: 1262.6598680019379\n",
      "Training Adam optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0965 - acc: 0.0178 - val_loss: 4.8952 - val_acc: 0.0299\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8205 - acc: 0.0417 - val_loss: 4.7447 - val_acc: 0.0509\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6866 - acc: 0.0571 - val_loss: 4.5761 - val_acc: 0.0669\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6143 - acc: 0.0668 - val_loss: 4.5785 - val_acc: 0.0728\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.5593 - acc: 0.0725 - val_loss: 4.4372 - val_acc: 0.0892\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5140 - acc: 0.0789 - val_loss: 4.4026 - val_acc: 0.0900\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4832 - acc: 0.0830 - val_loss: 4.3598 - val_acc: 0.0928\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4575 - acc: 0.0864 - val_loss: 4.3902 - val_acc: 0.0927\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4373 - acc: 0.0878 - val_loss: 4.3357 - val_acc: 0.0946\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.4237 - acc: 0.0921 - val_loss: 4.2881 - val_acc: 0.1063\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4028 - acc: 0.0947 - val_loss: 4.2807 - val_acc: 0.1066\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3895 - acc: 0.0939 - val_loss: 4.2722 - val_acc: 0.1095\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3794 - acc: 0.0961 - val_loss: 4.3096 - val_acc: 0.0978\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3692 - acc: 0.0978 - val_loss: 4.2746 - val_acc: 0.1081\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3567 - acc: 0.0993 - val_loss: 4.2947 - val_acc: 0.1042\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3505 - acc: 0.0995 - val_loss: 4.2971 - val_acc: 0.1047\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3405 - acc: 0.1010 - val_loss: 4.3333 - val_acc: 0.1008\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3293 - acc: 0.1024 - val_loss: 4.3080 - val_acc: 0.1045\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3224 - acc: 0.1049 - val_loss: 4.3303 - val_acc: 0.1013\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3223 - acc: 0.1042 - val_loss: 4.2657 - val_acc: 0.1072\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3099 - acc: 0.1043 - val_loss: 4.3233 - val_acc: 0.1013\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3095 - acc: 0.1053 - val_loss: 4.2924 - val_acc: 0.1033\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3026 - acc: 0.1067 - val_loss: 4.3895 - val_acc: 0.0916\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2946 - acc: 0.1070 - val_loss: 4.2164 - val_acc: 0.1128\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2899 - acc: 0.1073 - val_loss: 4.3408 - val_acc: 0.1001\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2903 - acc: 0.1092 - val_loss: 4.3740 - val_acc: 0.0985\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2843 - acc: 0.1087 - val_loss: 4.2863 - val_acc: 0.1046\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2851 - acc: 0.1079 - val_loss: 4.4584 - val_acc: 0.0920\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2809 - acc: 0.1087 - val_loss: 4.2481 - val_acc: 0.1099\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.2800 - acc: 0.1095 - val_loss: 4.3652 - val_acc: 0.1003\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2733 - acc: 0.1094 - val_loss: 4.4724 - val_acc: 0.0872\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2753 - acc: 0.1090 - val_loss: 4.4147 - val_acc: 0.0933\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2731 - acc: 0.1104 - val_loss: 4.4046 - val_acc: 0.0945\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2683 - acc: 0.1107 - val_loss: 4.2749 - val_acc: 0.1085\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2671 - acc: 0.1116 - val_loss: 4.4116 - val_acc: 0.0955\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2685 - acc: 0.1107 - val_loss: 4.3535 - val_acc: 0.1012\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2731 - acc: 0.1097 - val_loss: 4.3932 - val_acc: 0.0956\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2579 - acc: 0.1112 - val_loss: 4.3234 - val_acc: 0.1040\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2640 - acc: 0.1125 - val_loss: 4.4533 - val_acc: 0.0902\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2662 - acc: 0.1137 - val_loss: 4.1907 - val_acc: 0.1185\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2662 - acc: 0.1123 - val_loss: 4.2816 - val_acc: 0.1116\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2613 - acc: 0.1114 - val_loss: 4.3101 - val_acc: 0.1063\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2611 - acc: 0.1119 - val_loss: 4.2204 - val_acc: 0.1166\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2605 - acc: 0.1109 - val_loss: 4.2764 - val_acc: 0.1058\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2574 - acc: 0.1130 - val_loss: 4.2668 - val_acc: 0.1137\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2592 - acc: 0.1112 - val_loss: 4.3270 - val_acc: 0.1042\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2568 - acc: 0.1130 - val_loss: 4.3752 - val_acc: 0.1067\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2522 - acc: 0.1139 - val_loss: 4.4173 - val_acc: 0.1002\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2634 - acc: 0.1121 - val_loss: 4.3263 - val_acc: 0.1034\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2543 - acc: 0.1131 - val_loss: 4.3930 - val_acc: 0.1026\n",
      "10000/10000 [==============================] - 1s 134us/step\n",
      "Test loss: 4.3929524444580075\n",
      "Test accuracy: 0.1026\n",
      "Runtime: 1263.0200555324554\n",
      "Training Adamax optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0345 - acc: 0.0236 - val_loss: 4.7009 - val_acc: 0.0564\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7080 - acc: 0.0551 - val_loss: 4.5171 - val_acc: 0.0746\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5419 - acc: 0.0752 - val_loss: 4.3767 - val_acc: 0.0951\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4225 - acc: 0.0909 - val_loss: 4.2819 - val_acc: 0.1037\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3299 - acc: 0.1016 - val_loss: 4.2269 - val_acc: 0.1137\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.2508 - acc: 0.1115 - val_loss: 4.2133 - val_acc: 0.1182\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1919 - acc: 0.1198 - val_loss: 4.2008 - val_acc: 0.1196\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1395 - acc: 0.1274 - val_loss: 4.2256 - val_acc: 0.1211\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0945 - acc: 0.1344 - val_loss: 3.9639 - val_acc: 0.1474\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0608 - acc: 0.1384 - val_loss: 4.0020 - val_acc: 0.1452\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0259 - acc: 0.1429 - val_loss: 4.0745 - val_acc: 0.1375\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0005 - acc: 0.1482 - val_loss: 4.0282 - val_acc: 0.1439\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9784 - acc: 0.1506 - val_loss: 4.1686 - val_acc: 0.1372\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9515 - acc: 0.1537 - val_loss: 4.0776 - val_acc: 0.1390\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9394 - acc: 0.1557 - val_loss: 3.9187 - val_acc: 0.1604\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9201 - acc: 0.1574 - val_loss: 4.1063 - val_acc: 0.1400\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9023 - acc: 0.1612 - val_loss: 4.0555 - val_acc: 0.1416\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8921 - acc: 0.1617 - val_loss: 3.9654 - val_acc: 0.1545\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8796 - acc: 0.1643 - val_loss: 4.1267 - val_acc: 0.1429\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8709 - acc: 0.1657 - val_loss: 4.0197 - val_acc: 0.1494\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.8592 - acc: 0.1653 - val_loss: 3.9879 - val_acc: 0.1573\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8468 - acc: 0.1691 - val_loss: 4.0342 - val_acc: 0.1536\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.8388 - acc: 0.1703 - val_loss: 3.9356 - val_acc: 0.1614\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8321 - acc: 0.1708 - val_loss: 4.1513 - val_acc: 0.1426\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8268 - acc: 0.1724 - val_loss: 4.1608 - val_acc: 0.1414\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8159 - acc: 0.1736 - val_loss: 3.9125 - val_acc: 0.1675\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8090 - acc: 0.1752 - val_loss: 3.9005 - val_acc: 0.1616\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8079 - acc: 0.1755 - val_loss: 3.9510 - val_acc: 0.1600\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8002 - acc: 0.1782 - val_loss: 3.9206 - val_acc: 0.1619\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7930 - acc: 0.1788 - val_loss: 3.9662 - val_acc: 0.1561\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7848 - acc: 0.1792 - val_loss: 3.9301 - val_acc: 0.1612\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7789 - acc: 0.1785 - val_loss: 4.0269 - val_acc: 0.1534\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7763 - acc: 0.1813 - val_loss: 3.8668 - val_acc: 0.1657\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7723 - acc: 0.1813 - val_loss: 3.9717 - val_acc: 0.1627\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7678 - acc: 0.1807 - val_loss: 3.9299 - val_acc: 0.1635\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7651 - acc: 0.1815 - val_loss: 4.0389 - val_acc: 0.1567\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7609 - acc: 0.1834 - val_loss: 4.0134 - val_acc: 0.1567\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7574 - acc: 0.1839 - val_loss: 3.9903 - val_acc: 0.1637\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7574 - acc: 0.1833 - val_loss: 3.9944 - val_acc: 0.1603\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.7556 - acc: 0.1844 - val_loss: 3.9192 - val_acc: 0.1669\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7541 - acc: 0.1847 - val_loss: 4.1489 - val_acc: 0.1478\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7437 - acc: 0.1858 - val_loss: 4.0003 - val_acc: 0.1605\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7446 - acc: 0.1870 - val_loss: 3.9191 - val_acc: 0.1681\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7437 - acc: 0.1851 - val_loss: 4.1093 - val_acc: 0.1461\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7355 - acc: 0.1878 - val_loss: 3.8030 - val_acc: 0.1830\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7348 - acc: 0.1875 - val_loss: 4.1099 - val_acc: 0.1473\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7377 - acc: 0.1880 - val_loss: 3.9745 - val_acc: 0.1631\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7319 - acc: 0.1881 - val_loss: 3.8988 - val_acc: 0.1699\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7341 - acc: 0.1887 - val_loss: 3.8352 - val_acc: 0.1756\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7227 - acc: 0.1888 - val_loss: 3.8749 - val_acc: 0.1749\n",
      "10000/10000 [==============================] - 1s 137us/step\n",
      "Test loss: 3.8749251670837404\n",
      "Test accuracy: 0.1749\n",
      "Runtime: 1265.916042804718\n",
      "Training Nadam optimizer\n",
      "Epoch 1/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3004 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 2/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 3/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 4/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 5/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 6/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 7/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0045 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 8/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 9/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3009 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 10/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 11/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 12/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 13/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 14/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 15/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 16/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0048 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 17/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 18/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 19/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 20/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 21/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 22/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 23/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 24/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 25/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 26/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3001 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 27/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 28/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 29/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 30/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3003 - acc: 0.0043 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 31/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0045 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 32/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 33/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3003 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 34/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 35/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 36/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 37/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 38/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 39/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0042 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 40/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 41/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0044 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 42/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2986 - val_acc: 0.0050\n",
      "Epoch 43/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3001 - acc: 0.0046 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 44/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 45/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0047 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 46/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0048 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 47/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0042 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 48/50\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.3002 - acc: 0.0046 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "Epoch 49/50\n",
      "3125/3125 [==============================] - 27s 9ms/step - loss: 5.3001 - acc: 0.0049 - val_loss: 5.2988 - val_acc: 0.0050\n",
      "Epoch 50/50\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.3002 - acc: 0.0043 - val_loss: 5.2987 - val_acc: 0.0050\n",
      "10000/10000 [==============================] - 1s 132us/step\n",
      "Test loss: 5.298713544464111\n",
      "Test accuracy: 0.005\n",
      "Runtime: 1269.412302017212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opts = [('SGD', SGD()), ('RMSprop', RMSprop()), ('Adagrad', Adagrad()), ('Adadelta', Adadelta()), \n",
    "        ('Adam', Adam()), ('Adamax', Adamax()), ('Nadam', Nadam())]\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 200\n",
    "epochs = 50\n",
    "\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "for name, opt in opts:\n",
    "    print('Training ' + name + ' optimizer')\n",
    "    logs = \"logs/optimizer/\"+name\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    \n",
    "    model_name = name + '_keras_imagenet200_base.h5'\n",
    "    \n",
    "    model_base = Sequential()\n",
    "    model_base.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=train_images.shape[1:]))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(32, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(64, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Flatten())\n",
    "    model_base.add(Dense(512))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(num_classes))\n",
    "    model_base.add(Activation('softmax'))\n",
    "    \n",
    "    # Let's train the model using RMSprop\n",
    "    model_base.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model_base.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                                     epochs=epochs,\n",
    "                                     validation_data=(val_images, y_test),\n",
    "                                     workers=4,\n",
    "                                     steps_per_epoch=len(train_images)/batch_size, \n",
    "                                     callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model_base.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model_base.evaluate(val_images, y_test, verbose=1)\n",
    "\n",
    "    end = time()\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD optimizer\n",
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 5.2978 - acc: 0.0048 - val_loss: 5.2914 - val_acc: 0.0053\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.2566 - acc: 0.0070 - val_loss: 5.2114 - val_acc: 0.0113\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1814 - acc: 0.0107 - val_loss: 5.1011 - val_acc: 0.0162\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1120 - acc: 0.0160 - val_loss: 5.0289 - val_acc: 0.0247\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.0430 - acc: 0.0225 - val_loss: 4.9140 - val_acc: 0.0413\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.9505 - acc: 0.0305 - val_loss: 4.7935 - val_acc: 0.0493\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.8572 - acc: 0.0385 - val_loss: 4.6980 - val_acc: 0.0610\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7894 - acc: 0.0457 - val_loss: 4.6174 - val_acc: 0.0700\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7283 - acc: 0.0530 - val_loss: 4.5622 - val_acc: 0.0761\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6762 - acc: 0.0597 - val_loss: 4.5028 - val_acc: 0.0826\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.6283 - acc: 0.0658 - val_loss: 4.4490 - val_acc: 0.0928\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5856 - acc: 0.0707 - val_loss: 4.4542 - val_acc: 0.0903\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5448 - acc: 0.0769 - val_loss: 4.3673 - val_acc: 0.1004\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5090 - acc: 0.0809 - val_loss: 4.3171 - val_acc: 0.1106\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4733 - acc: 0.0854 - val_loss: 4.3042 - val_acc: 0.1090\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4412 - acc: 0.0906 - val_loss: 4.2935 - val_acc: 0.1074\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4113 - acc: 0.0938 - val_loss: 4.2629 - val_acc: 0.1123\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3824 - acc: 0.0975 - val_loss: 4.2421 - val_acc: 0.1155\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3581 - acc: 0.1006 - val_loss: 4.1927 - val_acc: 0.1182\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3344 - acc: 0.1043 - val_loss: 4.1509 - val_acc: 0.1295\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.3082 - acc: 0.1055 - val_loss: 4.1397 - val_acc: 0.1275\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2863 - acc: 0.1096 - val_loss: 4.1648 - val_acc: 0.1215\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2663 - acc: 0.1119 - val_loss: 4.2415 - val_acc: 0.1146\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2432 - acc: 0.1153 - val_loss: 4.1483 - val_acc: 0.1254\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2267 - acc: 0.1169 - val_loss: 4.0898 - val_acc: 0.1337\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2084 - acc: 0.1197 - val_loss: 4.1234 - val_acc: 0.1314\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1926 - acc: 0.1211 - val_loss: 4.1774 - val_acc: 0.1235\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1739 - acc: 0.1240 - val_loss: 4.0991 - val_acc: 0.1350\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1597 - acc: 0.1264 - val_loss: 4.1126 - val_acc: 0.1360\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1396 - acc: 0.1281 - val_loss: 4.1366 - val_acc: 0.1277\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1227 - acc: 0.1307 - val_loss: 4.0530 - val_acc: 0.1402\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1140 - acc: 0.1315 - val_loss: 4.1413 - val_acc: 0.1268\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1002 - acc: 0.1344 - val_loss: 4.0272 - val_acc: 0.1422\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0838 - acc: 0.1379 - val_loss: 4.0143 - val_acc: 0.1459\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0721 - acc: 0.1371 - val_loss: 4.1575 - val_acc: 0.1293\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0598 - acc: 0.1398 - val_loss: 4.0967 - val_acc: 0.1327\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0470 - acc: 0.1404 - val_loss: 4.0948 - val_acc: 0.1373\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0394 - acc: 0.1425 - val_loss: 4.0772 - val_acc: 0.1373\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0176 - acc: 0.1471 - val_loss: 3.9937 - val_acc: 0.1519\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0118 - acc: 0.1464 - val_loss: 4.1441 - val_acc: 0.1336\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0005 - acc: 0.1483 - val_loss: 4.0351 - val_acc: 0.1436\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9909 - acc: 0.1485 - val_loss: 3.9878 - val_acc: 0.1510\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9766 - acc: 0.1505 - val_loss: 3.9808 - val_acc: 0.1493\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9693 - acc: 0.1498 - val_loss: 4.0263 - val_acc: 0.1437\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9614 - acc: 0.1523 - val_loss: 4.1672 - val_acc: 0.1319\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9497 - acc: 0.1552 - val_loss: 4.1010 - val_acc: 0.1381\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9425 - acc: 0.1565 - val_loss: 4.0455 - val_acc: 0.1410\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9339 - acc: 0.1567 - val_loss: 4.0941 - val_acc: 0.1360\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9260 - acc: 0.1568 - val_loss: 3.9734 - val_acc: 0.1506\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9162 - acc: 0.1598 - val_loss: 3.9749 - val_acc: 0.1555\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9083 - acc: 0.1596 - val_loss: 4.0289 - val_acc: 0.1436\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8988 - acc: 0.1603 - val_loss: 3.9225 - val_acc: 0.1585\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8943 - acc: 0.1613 - val_loss: 4.0598 - val_acc: 0.1417\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8823 - acc: 0.1633 - val_loss: 4.1442 - val_acc: 0.1352\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8770 - acc: 0.1638 - val_loss: 3.9457 - val_acc: 0.1568\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8722 - acc: 0.1652 - val_loss: 4.0240 - val_acc: 0.1449\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8628 - acc: 0.1660 - val_loss: 3.9512 - val_acc: 0.1569\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8568 - acc: 0.1661 - val_loss: 3.9511 - val_acc: 0.1550\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8485 - acc: 0.1685 - val_loss: 3.8387 - val_acc: 0.1743\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8400 - acc: 0.1714 - val_loss: 3.8834 - val_acc: 0.1654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8347 - acc: 0.1702 - val_loss: 3.9722 - val_acc: 0.1563\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8319 - acc: 0.1726 - val_loss: 3.8830 - val_acc: 0.1672\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8224 - acc: 0.1729 - val_loss: 3.9292 - val_acc: 0.1556\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8196 - acc: 0.1738 - val_loss: 3.9330 - val_acc: 0.1590\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8114 - acc: 0.1730 - val_loss: 3.9807 - val_acc: 0.1548\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8100 - acc: 0.1739 - val_loss: 3.9770 - val_acc: 0.1522\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7995 - acc: 0.1750 - val_loss: 3.9320 - val_acc: 0.1594\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7882 - acc: 0.1770 - val_loss: 3.8741 - val_acc: 0.1684\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7821 - acc: 0.1797 - val_loss: 3.9608 - val_acc: 0.1546\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7825 - acc: 0.1788 - val_loss: 4.1162 - val_acc: 0.1451\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7777 - acc: 0.1796 - val_loss: 3.9798 - val_acc: 0.1558\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7682 - acc: 0.1804 - val_loss: 3.9615 - val_acc: 0.1563\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7646 - acc: 0.1801 - val_loss: 3.9591 - val_acc: 0.1600\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7652 - acc: 0.1812 - val_loss: 4.0223 - val_acc: 0.1529\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7545 - acc: 0.1809 - val_loss: 3.8710 - val_acc: 0.1691\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7545 - acc: 0.1826 - val_loss: 3.8765 - val_acc: 0.1691\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7423 - acc: 0.1846 - val_loss: 3.8410 - val_acc: 0.1736\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7458 - acc: 0.1840 - val_loss: 3.9373 - val_acc: 0.1610\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7404 - acc: 0.1837 - val_loss: 3.8815 - val_acc: 0.1686\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7358 - acc: 0.1840 - val_loss: 3.9605 - val_acc: 0.1574\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7234 - acc: 0.1864 - val_loss: 3.8920 - val_acc: 0.1668\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7255 - acc: 0.1871 - val_loss: 3.8221 - val_acc: 0.1797\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7218 - acc: 0.1880 - val_loss: 3.8588 - val_acc: 0.1742\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7143 - acc: 0.1881 - val_loss: 3.9173 - val_acc: 0.1651\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7152 - acc: 0.1908 - val_loss: 3.8380 - val_acc: 0.1724\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7110 - acc: 0.1900 - val_loss: 3.9085 - val_acc: 0.1645\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7016 - acc: 0.1900 - val_loss: 3.8850 - val_acc: 0.1690\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7003 - acc: 0.1909 - val_loss: 3.9769 - val_acc: 0.1528\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7003 - acc: 0.1912 - val_loss: 3.9775 - val_acc: 0.1574\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6968 - acc: 0.1912 - val_loss: 3.7551 - val_acc: 0.1833\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6935 - acc: 0.1923 - val_loss: 3.9341 - val_acc: 0.1621\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6860 - acc: 0.1916 - val_loss: 3.8939 - val_acc: 0.1653\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6816 - acc: 0.1947 - val_loss: 3.8924 - val_acc: 0.1737\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6794 - acc: 0.1922 - val_loss: 3.8845 - val_acc: 0.1668\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6752 - acc: 0.1939 - val_loss: 3.8993 - val_acc: 0.1630\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6728 - acc: 0.1944 - val_loss: 3.8600 - val_acc: 0.1754\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6650 - acc: 0.1948 - val_loss: 3.9931 - val_acc: 0.1585\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6646 - acc: 0.1953 - val_loss: 4.0023 - val_acc: 0.1559\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6631 - acc: 0.1972 - val_loss: 3.9016 - val_acc: 0.1655\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6604 - acc: 0.1969 - val_loss: 3.7905 - val_acc: 0.1810\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "Test loss: 3.790474868011475\n",
      "Test accuracy: 0.181\n",
      "Runtime: 2496.592635154724\n",
      "Training Adamax optimizer\n",
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 5.1291 - acc: 0.0164 - val_loss: 4.8706 - val_acc: 0.0384\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.7691 - acc: 0.0489 - val_loss: 4.5008 - val_acc: 0.0828\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.5444 - acc: 0.0749 - val_loss: 4.3769 - val_acc: 0.0910\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.4032 - acc: 0.0927 - val_loss: 4.2911 - val_acc: 0.1041\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2964 - acc: 0.1059 - val_loss: 4.1664 - val_acc: 0.1213\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.2246 - acc: 0.1167 - val_loss: 4.1426 - val_acc: 0.1256\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1653 - acc: 0.1238 - val_loss: 4.1263 - val_acc: 0.1234\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.1192 - acc: 0.1286 - val_loss: 4.0455 - val_acc: 0.1377\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0751 - acc: 0.1359 - val_loss: 4.0399 - val_acc: 0.1353\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 4.0450 - acc: 0.1399 - val_loss: 4.0614 - val_acc: 0.1362\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 4.0207 - acc: 0.1425 - val_loss: 4.1567 - val_acc: 0.1283\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9927 - acc: 0.1483 - val_loss: 4.1383 - val_acc: 0.1296\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9742 - acc: 0.1506 - val_loss: 4.0987 - val_acc: 0.1343\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9543 - acc: 0.1522 - val_loss: 3.9434 - val_acc: 0.1588\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9341 - acc: 0.1563 - val_loss: 4.0152 - val_acc: 0.1451\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.9177 - acc: 0.1590 - val_loss: 4.0619 - val_acc: 0.1411\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.9010 - acc: 0.1610 - val_loss: 4.0138 - val_acc: 0.1446\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8924 - acc: 0.1619 - val_loss: 3.9476 - val_acc: 0.1545\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8811 - acc: 0.1638 - val_loss: 3.9382 - val_acc: 0.1564\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8689 - acc: 0.1661 - val_loss: 3.9279 - val_acc: 0.1599\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8625 - acc: 0.1668 - val_loss: 4.0003 - val_acc: 0.1500\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8516 - acc: 0.1675 - val_loss: 4.0299 - val_acc: 0.1457\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8395 - acc: 0.1702 - val_loss: 3.8666 - val_acc: 0.1681\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8369 - acc: 0.1707 - val_loss: 3.9074 - val_acc: 0.1637\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8252 - acc: 0.1715 - val_loss: 4.0933 - val_acc: 0.1457\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8224 - acc: 0.1725 - val_loss: 4.0738 - val_acc: 0.1420\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8154 - acc: 0.1747 - val_loss: 3.8028 - val_acc: 0.1772\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8039 - acc: 0.1757 - val_loss: 4.0321 - val_acc: 0.1513\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.8054 - acc: 0.1762 - val_loss: 4.0096 - val_acc: 0.1510\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7947 - acc: 0.1771 - val_loss: 3.9246 - val_acc: 0.1626\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7942 - acc: 0.1786 - val_loss: 4.0129 - val_acc: 0.1511\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.7924 - acc: 0.1782 - val_loss: 3.8847 - val_acc: 0.1673\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7831 - acc: 0.1791 - val_loss: 3.9709 - val_acc: 0.1626\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7784 - acc: 0.1799 - val_loss: 3.8866 - val_acc: 0.1677\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7759 - acc: 0.1823 - val_loss: 3.9920 - val_acc: 0.1593\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7766 - acc: 0.1806 - val_loss: 4.1213 - val_acc: 0.1431\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7722 - acc: 0.1798 - val_loss: 3.8062 - val_acc: 0.1727\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7652 - acc: 0.1831 - val_loss: 3.9379 - val_acc: 0.1572\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7606 - acc: 0.1821 - val_loss: 3.9975 - val_acc: 0.1596\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7560 - acc: 0.1825 - val_loss: 3.8917 - val_acc: 0.1708\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7522 - acc: 0.1839 - val_loss: 3.9538 - val_acc: 0.1620\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7522 - acc: 0.1845 - val_loss: 3.8968 - val_acc: 0.1706\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7480 - acc: 0.1858 - val_loss: 3.8617 - val_acc: 0.1715\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7479 - acc: 0.1845 - val_loss: 3.9688 - val_acc: 0.1595\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7479 - acc: 0.1845 - val_loss: 3.8251 - val_acc: 0.1776\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7434 - acc: 0.1862 - val_loss: 3.8918 - val_acc: 0.1723\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7402 - acc: 0.1872 - val_loss: 4.0433 - val_acc: 0.1557\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7381 - acc: 0.1862 - val_loss: 3.9057 - val_acc: 0.1766\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7375 - acc: 0.1862 - val_loss: 3.9328 - val_acc: 0.1658\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7376 - acc: 0.1870 - val_loss: 4.0422 - val_acc: 0.1523\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7350 - acc: 0.1875 - val_loss: 3.9205 - val_acc: 0.1641\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7339 - acc: 0.1878 - val_loss: 3.8939 - val_acc: 0.1672\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7281 - acc: 0.1895 - val_loss: 4.0192 - val_acc: 0.1596\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7233 - acc: 0.1893 - val_loss: 3.9198 - val_acc: 0.1693\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7256 - acc: 0.1874 - val_loss: 4.0742 - val_acc: 0.1531\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7251 - acc: 0.1902 - val_loss: 3.8804 - val_acc: 0.1728\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 3.7222 - acc: 0.1905 - val_loss: 4.0270 - val_acc: 0.1568\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7159 - acc: 0.1898 - val_loss: 3.9490 - val_acc: 0.1649\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7179 - acc: 0.1901 - val_loss: 4.0360 - val_acc: 0.1524\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7153 - acc: 0.1907 - val_loss: 3.9637 - val_acc: 0.1684\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7176 - acc: 0.1900 - val_loss: 3.8738 - val_acc: 0.1798\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7161 - acc: 0.1902 - val_loss: 3.8691 - val_acc: 0.1742\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7204 - acc: 0.1900 - val_loss: 4.0667 - val_acc: 0.1526\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7159 - acc: 0.1914 - val_loss: 4.1144 - val_acc: 0.1524\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7105 - acc: 0.1925 - val_loss: 3.8725 - val_acc: 0.1738\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7128 - acc: 0.1907 - val_loss: 4.1705 - val_acc: 0.1569\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7189 - acc: 0.1898 - val_loss: 4.0329 - val_acc: 0.1597\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7118 - acc: 0.1907 - val_loss: 3.8534 - val_acc: 0.1775\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7091 - acc: 0.1916 - val_loss: 3.8631 - val_acc: 0.1779\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7055 - acc: 0.1946 - val_loss: 3.8624 - val_acc: 0.1856\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7107 - acc: 0.1921 - val_loss: 3.9683 - val_acc: 0.1618\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7104 - acc: 0.1933 - val_loss: 3.8502 - val_acc: 0.1864\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7042 - acc: 0.1936 - val_loss: 3.8229 - val_acc: 0.1819\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7108 - acc: 0.1924 - val_loss: 3.8543 - val_acc: 0.1724\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7112 - acc: 0.1929 - val_loss: 3.9549 - val_acc: 0.1662\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7030 - acc: 0.1928 - val_loss: 3.9490 - val_acc: 0.1732\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7114 - acc: 0.1927 - val_loss: 3.7943 - val_acc: 0.1828\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7042 - acc: 0.1932 - val_loss: 3.9577 - val_acc: 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7080 - acc: 0.1926 - val_loss: 3.9969 - val_acc: 0.1618\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7064 - acc: 0.1939 - val_loss: 3.9885 - val_acc: 0.1655\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7044 - acc: 0.1917 - val_loss: 3.9069 - val_acc: 0.1779\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7050 - acc: 0.1929 - val_loss: 3.8028 - val_acc: 0.1826\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6972 - acc: 0.1929 - val_loss: 3.9967 - val_acc: 0.1696\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7009 - acc: 0.1936 - val_loss: 3.8741 - val_acc: 0.1747\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7062 - acc: 0.1946 - val_loss: 3.8964 - val_acc: 0.1763\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7021 - acc: 0.1943 - val_loss: 4.0409 - val_acc: 0.1685\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6995 - acc: 0.1941 - val_loss: 3.8420 - val_acc: 0.1844\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6968 - acc: 0.1949 - val_loss: 3.9136 - val_acc: 0.1747\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7029 - acc: 0.1951 - val_loss: 3.9067 - val_acc: 0.1718\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6987 - acc: 0.1944 - val_loss: 3.8877 - val_acc: 0.1762\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6992 - acc: 0.1947 - val_loss: 4.0369 - val_acc: 0.1665\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7039 - acc: 0.1930 - val_loss: 4.0264 - val_acc: 0.1649\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7025 - acc: 0.1945 - val_loss: 3.9214 - val_acc: 0.1722\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7006 - acc: 0.1933 - val_loss: 4.0065 - val_acc: 0.1685\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7018 - acc: 0.1931 - val_loss: 3.8697 - val_acc: 0.1767\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6989 - acc: 0.1942 - val_loss: 4.0194 - val_acc: 0.1660\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6990 - acc: 0.1950 - val_loss: 3.9220 - val_acc: 0.1786\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6999 - acc: 0.1932 - val_loss: 4.0216 - val_acc: 0.1637\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.6951 - acc: 0.1958 - val_loss: 3.8394 - val_acc: 0.1862\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 3.7002 - acc: 0.1941 - val_loss: 3.9430 - val_acc: 0.1747\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "Test loss: 3.9429873306274414\n",
      "Test accuracy: 0.1747\n",
      "Runtime: 2517.3177618980408\n"
     ]
    }
   ],
   "source": [
    "opts = [('SGD', SGD()), ('Adamax', Adamax())]\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 200\n",
    "epochs = 100\n",
    "\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "for name, opt in opts:\n",
    "    print('Training ' + name + ' optimizer')\n",
    "    logs = \"logs/optimizer/100/\"+name\n",
    "    tensorboard = TensorBoard(log_dir=logs)\n",
    "    \n",
    "    model_name = name + '_100_keras_imagenet200_base.h5'\n",
    "    \n",
    "    model_base = Sequential()\n",
    "    model_base.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=train_images.shape[1:]))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(32, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Conv2D(64, (3, 3)))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_base.add(Dropout(0.25))\n",
    "\n",
    "    model_base.add(Flatten())\n",
    "    model_base.add(Dense(512))\n",
    "    model_base.add(Activation('relu'))\n",
    "    model_base.add(Dropout(0.5))\n",
    "    model_base.add(Dense(num_classes))\n",
    "    model_base.add(Activation('softmax'))\n",
    "    \n",
    "    # Let's train the model using RMSprop\n",
    "    model_base.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(train_images)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model_base.fit_generator(datagen.flow(train_images, y_train, batch_size=batch_size),\n",
    "                                     epochs=epochs,\n",
    "                                     validation_data=(val_images, y_test),\n",
    "                                     workers=4,\n",
    "                                     steps_per_epoch=len(train_images)/batch_size, \n",
    "                                     callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model and weights\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model_base.save(model_path)\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model_base.evaluate(val_images, y_test, verbose=1)\n",
    "\n",
    "    end = time()\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print('Runtime:', str(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
